FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=0.630000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=2.40999999999999998945e-02
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=17 7 3 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 5, 6.99999999999999955591e-01) (11, 5, 6.99999999999999955591e-01) (11, 5, 6.99999999999999955591e-01) (11, 5, 6.99999999999999955591e-01) (11, 5, 6.99999999999999955591e-01) (11, 5, 6.99999999999999955591e-01) (0, 5, 6.99999999999999955591e-01) (5, 8, 4.50000000000000011102e-01) (5, 8, 4.50000000000000011102e-01) (0, 8, 4.50000000000000011102e-01) 
connections (connected_to_neuron, weight)=(16, -2.05179414529516823684e-01) (6, -4.24855525302639414065e+00) (15, -1.52626335382592319689e+01) (4, 5.17678915890975321901e+00) (13, 7.65889987503889990705e+00) (10, 1.34987117224752708466e+01) (2, 1.07327419712348586245e+01) (11, 5.08011114698359689257e-01) (5, -3.01067982726409955063e+00) (12, -1.18136649923599144074e+01) (9, -2.10831894884808601631e+00) (16, -2.18714999601098053494e-01) (2, 5.50290312797128233768e+00) (4, -3.75265743976195276232e+00) (3, 6.35859220016918502694e+00) (6, -5.13355251865675121792e+00) (13, 3.00529924262060932350e+00) (11, 3.03519246043102253196e+00) (12, -1.36304753531228373120e+00) (10, 1.70695937345281378850e-01) (8, 6.70946639134449274167e+00) (1, 9.00346120699045648905e+00) (16, -4.72548017767414618717e-01) (3, -5.70229175376157915167e-01) (5, 5.22878962552896098259e+00) (10, -2.93486951908942694800e+00) (13, -2.04148832281644321274e-01) (11, -6.61247728736218287615e-01) (7, 4.87139828637612681828e-01) (12, 2.88436754956711116638e-01) (1, -5.38431608182806220597e-01) (14, -1.83279771811997127529e+00) (8, -2.26717569837954746603e+00) (16, 1.17052798339796204630e+00) (7, 4.81089849382339540540e+00) (12, 2.90808275407611838137e-01) (14, -3.53085758464749055463e+00) (11, -2.32294491907370348471e+00) (13, -5.33894972602352746449e-01) (6, 2.13150065733717797301e+00) (2, -3.73317773977758404769e+00) (3, -1.07179323017047223310e+00) (10, -1.57703989053752868799e+00) (15, 1.82512299920876897019e+00) (16, -8.58939264361233356659e-01) (1, 8.72907266851913887784e-02) (8, -1.38318602651792565972e+00) (7, 1.08544013791252513812e+00) (4, 1.52911210183447510147e+00) (15, -1.36057988888515146719e+00) (9, -9.24781176974530216839e-01) (11, -1.71897718704679669521e+00) (3, -2.85102779025402541802e-01) (10, -3.03720321965973916178e+00) (12, -2.47514555310201078697e+00) (16, -5.86523355582025063271e-01) (0, -1.40539570677890535144e+00) (9, -6.53229095476766441486e-01) (11, -8.12275247094238705969e-01) (15, -5.70949719140125266925e-01) (3, -5.76377465975958958033e-01) (14, -1.81243632983583313756e-01) (13, -6.33642629334963958243e-01) (8, -2.81673145323491802561e-01) (1, -2.41274665455673026360e-01) (6, 8.39135899946362062707e-01) (23, 6.49663636643584951891e-01) (17, -1.55070044828588904373e+00) (18, -8.01318548770178606944e-01) (21, 1.46745837419782726441e-01) (22, 1.19290209349513065540e+00) (23, -1.17425496512354121670e+00) (19, 3.73574909197222804202e-01) (20, 2.68263018901458361043e+00) (21, 7.96391646292575083876e-01) (22, 4.44697738624078020564e+00) 
